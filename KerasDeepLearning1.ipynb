{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasDeepLearning1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/thomasawolff/Machine-Learning-Projects/blob/master/KerasDeepLearning1.ipynb",
      "authorship_tag": "ABX9TyOIu8j/pbMZ1C2MsZfuDySR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomasawolff/YouTube-Video-Comments-Project/blob/main/KerasDeepLearning1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQcensR9PEy5",
        "outputId": "c2f33503-213f-4e84-f67f-268ce79e02e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "import random\r\n",
        "import pickle\r\n",
        "import textwrap\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from textblob import TextBlob\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from datetime import datetime\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.metrics import classification_report,confusion_matrix\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "url = ('C:\\\\Users\\\\moose_f8sa3n2\\\\Google Drive\\\\Research Methods\\\\Course Project\\\\YouTube Data\\\\Unicode Files\\\\youTubeVideosUTF.csv')\r\n",
        "\r\n",
        "\r\n",
        "class textAnalytics(object):\r\n",
        "\r\n",
        "    def __init__(self,file1,\r\n",
        "                 numClusters=3,\r\n",
        "                 dataFeature1=None,\r\n",
        "                 dataFeature2=None,\r\n",
        "                 dataFeature3=None,\r\n",
        "                 dataFeature4=None,\r\n",
        "                 ):\r\n",
        "        self.number_clusters = numClusters\r\n",
        "        self.dataFeature1 = dataFeature1\r\n",
        "        self.dataFeature2 = dataFeature2\r\n",
        "        self.dataFeature3 = dataFeature3\r\n",
        "        self.dataFeature4 = dataFeature4\r\n",
        "        data_df = pd.read_csv(file1,low_memory=False)\r\n",
        "        self.token_pattern = '(?u)\\\\b\\\\w+\\\\b'\r\n",
        "        review_df_All = data_df[[self.dataFeature1,self.dataFeature2,self.dataFeature3,self.dataFeature4]]\r\n",
        "        videoTitles = pd.read_csv('YouTubeVideoTitles.csv')\r\n",
        "        self.dataComm = pd.merge(videoTitles, review_df_All, on = dataFeature1)\r\n",
        "        self.stopWords = stopwords.words('english')\r\n",
        "                \r\n",
        "\r\n",
        "    def sentimentAnalysis(self):\r\n",
        "        pol = []\r\n",
        "        sub = []\r\n",
        "        for i in self.dataComm.commentText.values:\r\n",
        "            try:\r\n",
        "                analysis = TextBlob(i)\r\n",
        "                pol.append(round(analysis.sentiment.polarity,2))\r\n",
        "            except:\r\n",
        "                pol.append(0)\r\n",
        "\r\n",
        "        for i in self.dataComm.commentText.values:\r\n",
        "            try:\r\n",
        "                analysis = TextBlob(i)\r\n",
        "                sub.append(round(analysis.sentiment.subjectivity,2))\r\n",
        "            except:\r\n",
        "                sub.append(0)\r\n",
        "        self.dataComm['polarity']=pol\r\n",
        "        self.dataComm['subjectivity']=sub\r\n",
        "        #print(self.dataComm['polarity'])\r\n",
        "        self.dataComm.loc[self.dataComm['polarity'] < 0, 'sentimentBucket'] = -1\r\n",
        "        self.dataComm.loc[self.dataComm['polarity'] == 0, 'sentimentBucket'] = 0\r\n",
        "        self.dataComm.loc[self.dataComm['polarity'] > 0, 'sentimentBucket'] = 1\r\n",
        "        #dataComm .to_csv('youTubeVideosSentimentAnalysisSample10000.csv',sep=',',encoding='utf-8')\r\n",
        "        ##                    videoID       categoryID  views  ...    replies  polarity   subjectivity\r\n",
        "        ##          251449  LLGENw4C1jk          17   1002386  ...      0.0      0.50          0.50\r\n",
        "        ##          39834   3VVnY86ulA8          22    802134  ...      0.0      0.00          0.10\r\n",
        "        ##          203460  iA86imHKCMw          17   3005399  ...      0.0     -0.08          0.69\r\n",
        "        ##          345225  RRkdV_xmYOI          23    367544  ...      0.0      0.13          0.76\r\n",
        "        ##          402953  vQ3XgMKAgxc          10  51204658  ...      0.0      0.25          0.50\r\n",
        "        \r\n",
        "\r\n",
        "        \r\n",
        "    def dataModify(self):\r\n",
        "        self.sentimentAnalysis()\r\n",
        "        self.dataComm  = self.dataComm[[self.dataFeature1,self.dataFeature2,self.dataFeature3,self.dataFeature4,\\\r\n",
        "                                        'polarity','subjectivity','sentimentBucket']]\r\n",
        "        # using the polarity and subjectivity data for k means\r\n",
        "        # accessing them by their index but calling them by column name\r\n",
        "        # iloc[:,[self.dataComm.columns.get_loc('polarity'): iloc calls for the index location of the\r\n",
        "        # column polarity which is called by column name through get_loc which returns the index position of that column\r\n",
        "        self.X = self.dataComm.iloc[:,[self.dataComm.columns.get_loc('polarity'),self.dataComm.columns.get_loc('subjectivity')]].values\r\n",
        "\r\n",
        "\r\n",
        "      \r\n",
        "    def kMeansClustering(self):\r\n",
        "        self.dataModify()\r\n",
        "        kmeans = KMeans(self.number_clusters, init = 'k-means++',max_iter=300,n_init=10)\r\n",
        "        self.dataComm['clusters'] = kmeans.fit_predict(self.X)\r\n",
        "        return self.dataComm\r\n",
        "\r\n",
        "\r\n",
        "go = textAnalytics(url,\r\n",
        "                   numClusters = 5,\r\n",
        "                   dataFeature1 = 'videoID', \r\n",
        "                   dataFeature2 = 'categoryID',\r\n",
        "                   dataFeature3 = 'views',\r\n",
        "                   dataFeature4 = 'commentText')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-aab9820bbf21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m                    \u001b[0mdataFeature2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categoryID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                    \u001b[0mdataFeature3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'views'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                    dataFeature4 = 'commentText')\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-aab9820bbf21>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file1, numClusters, dataFeature1, dataFeature2, dataFeature3, dataFeature4)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFeature3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataFeature3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFeature4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataFeature4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(?u)\\\\b\\\\w+\\\\b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mreview_df_All\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFeature1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFeature2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFeature3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFeature4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\moose_f8sa3n2\\\\Google Drive\\\\Research Methods\\\\Course Project\\\\YouTube Data\\\\Unicode Files\\\\youTubeVideosUTF.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGugqEjDhIdQ"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75_VEYWMhJN3"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}